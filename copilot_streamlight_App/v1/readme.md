# ğŸ§  Mini Copilot Streamlit App â€“ Full Documentation & Explanation

Welcome to your **AI Code Copilot** â€“ a Streamlit app that helps developers autocomplete code, generate unit tests, check coding style, and manage session history using both **local models (Ollama)** and **cloud models (OpenAI GPT-4)**.

This guide will walk you through each component like you're attending a class ğŸ‘¨â€ğŸ«.

---

## ğŸ¯ Goal of the App

This app is designed to simulate a **code assistant** like GitHub Copilot, but with:
- Full control over the backend model (local or cloud)
- Enhanced explainability (you can inspect everything)
- Extendability for teams or internal developer platforms

---

## ğŸ§± App Architecture (Big Picture)

```
Streamlit Frontend
â”œâ”€â”€ Code input area
â”œâ”€â”€ Model and language selection
â”œâ”€â”€ Buttons for actions (Autocomplete, Save, etc.)
â”œâ”€â”€ Output display
â””â”€â”€ Session manager (load/save)

Python Backend
â”œâ”€â”€ Model access functions (Ollama, OpenAI)
â”œâ”€â”€ Unit test generator
â”œâ”€â”€ Code style checker
â””â”€â”€ Session state management
```

---

## ğŸ§‘â€ğŸ’» Step-by-Step Explanation of Each Feature

### 1. ğŸ“ Code Editor

```python
user_code = st.text_area("âœï¸ Start writing your code:", ...)
```
A large input box where the user starts writing a code snippet (e.g., a function, a class). This is the core input for everything else.

---

### 2. ğŸ¤– Model Selection

```python
model_mode = st.selectbox("Choose model backend:", [...])
```
Lets you choose between:
- **Ollama (local)**: Fully offline inference using models like `codellama`
- **OpenAI GPT-4**: Cloud-based inference with higher quality and reliability

If you choose Ollama, another dropdown appears to let you pick the exact local model.

---

### 3. ğŸ§  Code Autocompletion

```python
if st.button("ğŸš€ Autocomplete Code"):
```

When you click this:
- The app wraps your code into a **prompt** that says:
  ```
  Complete the following <language> code:

  <your_code>

  ### Completion:
  ```
- Then it sends the prompt to the selected model and displays the response.
- Results are cached in `st.session_state["completion"]` so the UI persists.

---

### 4. ğŸ“‹ Copy to Clipboard

```python
pyperclip.copy(response)
```

Copies the completion output to the system clipboard using `pyperclip`. This allows quick reuse.

---

### 5. ğŸ’¾ Export to File

You can export the completion to a `.py` or `.md` file. A timestamped filename is generated automatically and the file is saved locally.

---

### 6. ğŸ“¥ Save Full Session

This saves:
- The userâ€™s code
- The AI-generated completion
- The selected model and language

Saved as a JSON file inside a `/saved_sessions` folder:
```json
{
  "user_code": "...",
  "completion": "...",
  "language": "python",
  "model_mode": "Ollama (local)",
  "ollama_model": "codellama"
}
```

---

### 7. ğŸ“‚ Load Session

From the sidebar, you can select and load a previously saved session. The UI updates with all saved settings and responses.

---

### 8. ğŸ§ª Unit Test Generator

```python
Write unit tests for the following <language> function:
<your code>
```

This prompt is sent to the LLM to generate matching unit tests. You can use this to:
- Check if your function behaves as expected
- Speed up TDD (Test-Driven Development)

---

### 9. ğŸ§± Code Style Checker

Uses simple logic to detect common issues, like:
- Semicolons in Python
- Too many lines in one function

> This can be extended with `flake8`, `pylint`, or any custom logic.

---

### 10. ğŸ§  Session State & Persistence

We use `st.session_state` to remember:
- The last completion
- Code language
- Model settings

This makes the app feel â€œstatefulâ€ â€” buttons work without wiping data.

---

## ğŸ“¦ Dependencies

```bash
pip install streamlit openai pyperclip
```

Also install and configure [Ollama](https://ollama.com) for local LLMs.

---

## ğŸ How to Run It

```bash
streamlit run copilot_app.py
```

---

## ğŸ¢ Why This Is Valuable for Companies

- âœ… Works offline (great for internal tools)
- âœ… Tracks developer input/output for auditing or retraining
- âœ… Extendable with linters, Docker file generation, docstring helpers
- âœ… Shows how to orchestrate multiple LLMs in a single app
- âœ… Encourages explainability and testing from day 1

---

## ğŸ”® Ideas to Extend

- Track token usage and OpenAI cost
- Version control integration (auto-commit to Git)
- Syntax-aware suggestions with tree-sitter or ast
- Autocomplete chat mode (conversational)

---

Made by devs, for devs ğŸ’»âœ¨